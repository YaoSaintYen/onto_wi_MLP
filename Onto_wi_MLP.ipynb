{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import deque\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anastasia', 'valentin', 'marko', 'sophie', 'rene', 'claudia', 'lorenz', 'hannah', 'paula', 'nico', 'dominik', 'nora']\n",
      "vocabulary_size: 12\n",
      "{'anastasia': 0, 'valentin': 1, 'marko': 2, 'sophie': 3, 'rene': 4, 'claudia': 5, 'lorenz': 6, 'hannah': 7, 'paula': 8, 'nico': 9, 'dominik': 10, 'nora': 11}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary = []\n",
    "# for sentence in tokenized_corpus:\n",
    "#     for token in sentence:\n",
    "#         if token not in vocabulary:\n",
    "#             vocabulary.append(token)\n",
    "\n",
    "vocabulary = [\"anastasia\", \"valentin\", \"marko\", \"sophie\", \"rene\", \"claudia\", \n",
    "              \"lorenz\", \"hannah\", \"paula\", \"nico\", \"dominik\", \"nora\"]\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "print (vocabulary)\n",
    "print (\"vocabulary_size: \" + str(vocabulary_size))\n",
    "print (word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_file     = \"/workdir2/home/sam/onto_oxford/relation_infer\"\n",
    "relations_file = \"/workdir2/home/sam/onto_oxford/relations\"\n",
    "\n",
    "with open(relations_file,'r') as f:\n",
    "    relation_number = 0\n",
    "    for line in f:\n",
    "        relation_number += 1\n",
    "        \n",
    "whole_dict     = {new_list: [] for new_list in range(relation_number)} \n",
    "wirelation     =  1\n",
    "worelation     =  0\n",
    "subject_index  =  1\n",
    "relation_index =  2\n",
    "object_index   =  3\n",
    "\n",
    "with open(infer_file,'r') as f:\n",
    "    for line in f:\n",
    "        relation = (line.strip())\n",
    "        if relation.split()[0]== \"+\":\n",
    "            whole_dict[int(relation.split()[relation_index])].append([wirelation, int(relation.split()[subject_index]), int(relation.split()[object_index])])\n",
    "        else:\n",
    "            whole_dict[int(relation.split()[relation_index])].append([worelation, int(relation.split()[subject_index]), int(relation.split()[object_index])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "print (whole_dict[21][4])\n",
    "# label, subject, object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round((y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_layer(word_idx):\n",
    "    x = torch.zeros(vocabulary_size).float()\n",
    "    x[word_idx] = 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding, voca_size, hidden_size):\n",
    "        \n",
    "        self.voca_size   = voca_size\n",
    "        self.embedding   = embedding\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        super(Siamese, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Linear(self.voca_size, self.embedding),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.liner = nn.Sequential(nn.Linear(self.embedding*2, self.hidden_size), nn.Sigmoid())\n",
    "        self.out   = nn.Sequential(nn.Linear(self.hidden_size, 1), nn.Sigmoid())\n",
    "        \n",
    "\n",
    "    def forward_one(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_one(x1)\n",
    "        out2 = self.forward_one(x2)\n",
    "        \n",
    "        dis = torch.cat((out1, out2), dim=0)\n",
    "        diss = self.liner(dis)\n",
    "        out = self.out(diss)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss(size_average=True)\n",
    "embedding_dims = 50\n",
    "hidden_size    = 10\n",
    "learning_rate  = 0.01\n",
    "net = Siamese(embedding_dims, vocabulary_size, hidden_size)\n",
    "net.train()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = learning_rate )\n",
    "optimizer.zero_grad()\n",
    "train_loss = []\n",
    "loss_val = 0\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1793130160205894\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931472395857174\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471923987071\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n",
      "0.6931471824645996\n",
      "Accuracy = 95.83333587646484\n"
     ]
    }
   ],
   "source": [
    "correct     = 0\n",
    "batch_print = 10\n",
    "for iewr in range(1, 500):\n",
    "    \n",
    "    for label, su, ob in whole_dict[5]:\n",
    "        optimizer.zero_grad()\n",
    "        su_onehot = Variable(get_input_layer(su)).float()\n",
    "        ob_onehot = Variable(get_input_layer(ob)).float()\n",
    "        output = net.forward(su_onehot, ob_onehot)\n",
    "        loss = loss_fn(output, torch.tensor([float(label)]))\n",
    "        loss_val += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        output = (output>0.5).float()\n",
    "        correct += (output == label).float().sum()\n",
    "    if iewr % batch_print ==0 and iewr != 0:\n",
    "        print(loss_val/len(whole_dict[23])/batch_print)\n",
    "        loss_val = 0\n",
    "        accuracy = 100 * (correct / batch_print) / len(whole_dict[21])\n",
    "        print(\"Accuracy = {}\".format(accuracy))\n",
    "        correct = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(Variable(get_input_layer(5)).float(), Variable(get_input_layer(10)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 2\n",
    "# 0 3\n",
    "# 3 11\n",
    "# 3 5\n",
    "# 5 10\n",
    "# 5 7\n",
    "# 8 4\n",
    "# 0 2\n",
    "# 0 3\n",
    "# 3 11\n",
    "# 3 5\n",
    "# 5 10\n",
    "\n",
    "# print (net.conv[0].weight.cpu().detach().numpy())\n",
    "# print ()\n",
    "# print (net.conv[0].weight.cpu().detach().numpy()[:, 2])\n",
    "# print ()\n",
    "# print (net.conv[0].weight[:, 2])\n",
    "# print ()\n",
    "# print (Variable(get_input_layer(2)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
